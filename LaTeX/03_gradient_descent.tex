\newpage
\thispagestyle{empty}
\section{Gradientenverfahren}\label{sec:gradientenverfahren}   
\begin{tcolorbox}[title={Inhalte des \textit{Gradientenverfahren}}]
  \begin{itemize}
    \item Wofür braucht mann das Gradientenverfahren?
    \item Grundkonzepte des Gradientenabstiegsverfahren
    \item Gefährliche Fehlerquellen
  \begin{quotation}\noindent
      Das Kapitel Gradientenverfahren stellt die Grundlagen dar, die für das Verständnis des Lernprozesses eines neuronalen Netzwerks im nachfolgenden Kapitel erforderlich sind.
  \end{quotation}
  \end{itemize}
\end{tcolorbox}


\subsection{Wofür braucht mann das Gradientenverfahren?}\label{subsec:gradientenverfahren:wofuer}
Das Gradientenverfahren (engl. gradient descent) wird genutzt, um das Minimum der Verlustfunktion zu finden (bzw. Optimierung generell). Dort ist der optimale Trainingszustand des Modells gefunden, weil dort der Fehler minimal ist.


\subsubsection{Was ist ein Gradient?}\label{subsec:gradientenverfahren:was_ist_gradient}
  %\input{}
  Ein Gradient ist ein Spaltenvektor der ersten partiellen Ableitung einer Funktion. 
  Dieser beschreibt immer die Richtung der größten (steilsten) Steigung in einem Punkt p in Form eines Vektors.\cite{JH20}



\subsection{Grundkonzepte des Gradientenverfahrens}\label{subsec:gradientenverfahren:grundkonzepte}
\subsubsection{Grundlage für den Fehlerrückführungs-Algorithmus - Wozu dient das Gradientenverfahren?}\label{subsec:gradientenverfahren:grundlage_fehlerrueckfuehrungsalg}
  %\input{}
  Warum sollte das Minimum der Verlustfunktion gefunden werden? Das spätere Lernen geschieht durch Anpassung der Gewichte, es wird die Differenz aus der tatsächlichen und der korrekten Ausgabe bestimmt. 
  Schnell kann hier natürlich die Frage aufkommen, warum nähert man sich dem Minimum an und berechnen es nicht. Die Berechnung würde auf das Problem stoßen, dass es unendlich viele Richtungen gibt, in der die Funktion minimal werden könnte. 

  Das Backpropagation-Verfahren ist eine Möglichkeit den Gradientenabstieg anzuwenden. Auf die Fehlerbestimmung wird in Kapitel 4 - Backpropagation eingegangen. Der Gradientenabstieg liefert also die Grundlage, später das NN zu trainieren.

\subsubsection{Wie funktioniert das Gradientenverfahren?}\label{subsec:gradientenverfahren:wie_funktioniert}
  %\input{}
  %verstehe noch nicht warum die Delta Regel hier steht @Max
  Bei der Delta Regel(bzw. allgemein beim Gradientenabstiegsverfahren) vergleicht man gewünscht und berechnete (Ausgabe-) Werte und nimmt mit Hilfe dieses Delta-Terms sukzessive
  Gewichtsveränderungen vor. Die Gewichte werden mit dem Gradientenabstiegsverfahren (bzw. im speziellen der Delta-Regel) modifiziert. Ziel ist ein Minimum der Fehlerfunktion per Näherungsverfahren zu finden.

  Das Verfahren durchläuft folgende Schritte:
  \begin{itemize}
    \item Wahl eines (zufälligen) Startpunktes
  \end{itemize}
  \begin{itemize}
    \item Festsetzung eines Lernparameters
  \end{itemize}
  \begin{itemize}
    \item Festlegung des Abbruchkriteriums
    \begin{itemize}
    \item Fixierung der kritischen Differrenz der Gewichtsveränderungen, die nicht unterschritten werden darf
    \item Spezifizierung der maximalen Anzahl an Iterationen (Wiederholungen), die vorgenommen werden sollen.
    \end{itemize}
  \end{itemize}
  \begin{itemize}
    \item  Berechnung des Gradienten
  \end{itemize}
  \begin{itemize}
    \item Veränderung der Gewichte
  \end{itemize}

  Der vierte und der fünfte Punkt werden solange wiederholt, bis mindestens eines der beiden Abbruchkriterien erfüllt ist (siehe dritter Punkt).
  Das Gradientenverfahren beginnt mit einer zufälligen Gewichtskombination, die die Startposition auf der Kurve bzw. in einer n-dimensionalen "Gebirgslandschaft" makiert.
  Von dieser Position aus soll nun das "tiefste Tal" in der "Hügellandschaft" gesucht werden.\cite{GR10}
  


  TODO: **Graphische Veranschaulichung, in 3-dim Raum **
\subsubsection{Mehrere Dimensionen}\label{subsec:gradientenverfahren:mehrere_dimensionen}
  %\input{}
  Das Gradientenverfahren beginnt mit einer zufälligen Gewichtskombination, die die Startposition auf der Kurve bzw. in einer n-dimensionalen "Gebirgslandschaft" makiert.
  Von dieser Position aus soll nun das "tiefste Tal" in der "Hügellandschaft" gesucht werden.
  Im zweidimensionmalen Raum kann ein Abstieg notwendigerweise nur nach links oder rechts erfolgen, während man sich im dreidimensionalen Raum einmal um seine eigene Achse drehen muss,
  um den steilsten Abstieg bestimmen zu können.

  Mathematisch ist der steilste Abstieg druch den sogenannten Gradienten(daher der Name Gradientenverfahren) repräsentiert bzw. genauer gesagt durch den negativen Gradienten, da der 
  Gradient selbst den stärksten Anstieg in der "Hügellandschaft" makiert. Der Gradient gibt nicht nur die Richtung, sondern zugleich auch die Steigung des "Hügels" an und stell folglich
  einen n-1-dimensionalen Vektor dar.\cite{GR10}


\subsection{Gefährliche Fehlerquellen}\label{subsec:gradientenverfahren:fehlerquellen}
\subsubsection{Steckt man in einem lokalen Minimum fest?}\label{subsec:gradientenverfahren:fehlerquellen_lokalen_minimum}
  %\input{}
  Auf der Suche nach einem Minimum, kann der Algorithmus in einem lokalen Minimum enden und so das erreichen eines globalen Minimums verhindert werden.
  Ein lokales Minimum tritt auf, wenn das Netzwerk in einem Punkt des Fehlergradienten auf eine niedrigere Fehlerfunktionsebene trifft, aber in der Nähe dieses Punktes einen anderen Punkt mit noch niedrigerem Fehler existiert.
  Da Neuronale Netze häufig große Anzahlen von Parametern haben, kann die Suche nach dem globalen Minimum eine schwierige Aufgabe sein.\cite{HS97}

\subsubsection{Befindet man sich wirklich im globalen Minimum?}\label{subsec:gradientenverfahren:fehlerquellen_globalen_minimum}
  %\input{}

  Gradientenabstiegs- und Suchverfahren finden in der Regel nur lokale Minima, abhängig vom gewählten Startpunkt. Durch die fehlende Kenntnis der gesamten n-dimensionalen "Hügellandschaft", die sich hinter 
  einem "Nebelschleier" verbirgt, ist de facto nie, (ausgenommen der gesamte Fehlerterm liegt bei Null (In diesem Fall ist gewährleistet, das es sich um ein globales Minimum handelt))
  sichergestellt, dass das Verfahren das "tiefte Tal" -d.h. das globale Minimum - findet.

\subsubsection{Wie löst man dieses Problem?}\label{subsec:gradientenverfahren:fehlerquellen_problem_loesen}
  %\input{}
  Gewichtsanpassung davor einbeziehen
  viele verschiedene Startpunkte testen?


